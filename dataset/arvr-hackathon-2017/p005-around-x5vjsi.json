{
    "source": "https://devpost.com/software/around-x5vjsi",
    "title": "ARound",
    "blurb": "Idea is to augment the world with spatial sounds that change depending on your proximity towards places",
    "awards": [
        "Best Everyday Mobile AR Hacks - 2nd",
        "1st Prize in Education, AR & VR for good"
    ],
    "videos": [
        "https://www.youtube.com/embed/NpU5qcs6Y6g?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
    ],
    "images": [
        {
            "title": "logo",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/546/836/datas/original.png"
        }
    ],
    "team": [
        {
            "name": "Anandana Kapur",
            "about": "Creative direction, features input, user validation, project management, Sound and film. ",
            "photo": "https://www.gravatar.com/avatar/aaa82345f2f0125b4bd6b899ec5083c4?d=https%3A%2F%2Fdevpost-challengepost.netdna-ssl.com%2Fassets%2Fdefaults%2Fno-avatar-180.png&s=180"
        },
        {
            "name": "Sunish Gupta",
            "about": "Experience Architect and Strategy; Integrating Usability and Accessibility (Inclusive Design)  ; Function/Feature/Task  Analysis selection and prioritization;,   Scenario creation and User Validation; System Design; Business Model, Marketing and Future Direction. ",
            "photo": "https://www.gravatar.com/avatar/3a4a0b424eb49465263ff3af0f859471?d=https%3A%2F%2Fdevpost-challengepost.netdna-ssl.com%2Fassets%2Fdefaults%2Fno-avatar-180.png&s=180"
        },
        {
            "name": "Dhara Bhavsar",
            "about": "Worked on the web app and the backend, configuring firebase on web and unity-android app, tech stack decision, managed Git repo, feature suggestions.",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/547/875/datas/profile.jpg"
        },
        {
            "name": "Maxym Nesmashny",
            "about": "Product design, research, usability testing, accessibility, spatial audio design, team formation and facilitation",
            "photo": "https://graph.facebook.com/10210348035205446/picture?height=180&width=180"
        },
        {
            "name": "Vedant Saran",
            "about": "",
            "photo": "https://www.gravatar.com/avatar/6468d0b21b172061e62cef9a18a37088?d=https%3A%2F%2Fdevpost-challengepost.netdna-ssl.com%2Fassets%2Fdefaults%2Fno-avatar-180.png&s=180"
        }
    ],
    "built_with": [
        "arcore",
        "css",
        "firebase",
        "google-maps",
        "html5",
        "javascript",
        "unity"
    ],
    "content_html": "<div>\n<p><strong>ARound</strong></p>\n<p><strong>Augmented Reality app for sound-based navigation</strong></p>\n<p><strong>Team ARound</strong></p>\n<p>Anandana Kapur, Dhara Bhavsar, Maxym Nesmashny, Sunish Gupta, Vedant Saran</p>\n<p><strong>User types</strong></p>\n<p>Visually impaired (sound reliant)</p>\n<p>Visually and hearing impaired (haptic feedback reliant)</p>\n<p>Mainstream (information and context reliant)</p>\n<p><strong>Why this app?</strong></p>\n<p>Team *<em>Getting ARound *</em> wants to augment the world with sound. Places of interest emit sounds that alert you of their presence, and that adds another layer of information to the world around us.  </p>\n<p>Spatial audio and ASMR related sounds can help to augment our everyday experiences and be a very powerful tool to navigate the world. </p>\n<p>Contextual audio cues that do not interfere with existing sounds or cause disorientation can be very valuable to navigate cities, forests, etc.</p>\n<p><strong>What does ARound do?</strong></p>\n<p>The  Augmented Reality app  <strong>ARound</strong>  equips all its users to independently navigate spaces by augmenting sounds of places, objects, and activities. In its current state the app functions using three modes:</p>\n<ol>\n<li><p><strong><em>Discovery mode</em></strong>: As you walk down a path, we use GPS data with combination of ARCore camera technology to sense your surroundings and trigger sounds of objects and locations on your path depending on your orientation towards them. The sounds are geofenced to an area so that they start playing just before you approach an object/place of interest, and gain in volume as you get closer. </p></li>\n<li><p><strong><em>Breadcrumb mode</em></strong>: As you walk around,  the app leaves a trail of sound along the path you have taken. If you lose your way or need to retrace your steps, you can simply follow your \"audio breadcrumbs\" to follow the path you took. Since the sound is anchored to the real-world, and we can accurately track the user\u2019s position using ARCore, the sound is spatialized to the user\u2019s orientation relative to the breadcrumbs. That makes it super easy to get back on the path - you just follow the direction the sound appears to be coming from. This feature gives the visually impaired the freedom and confidence to go on walks, hikes, or boating, without assistance. </p></li>\n<li><p><strong><em>Share mode</em></strong>: You can choose sounds from a library of audio files and link them to locations in the real world, through a web application. This creates a sound pin on the map that is triggered when the user approaches that location in the real world. This could be used to set up meetings with a blind person - You\u2019d just drop a pin of an audio note at the meeting location, and they\u2019d know when they arrived. There\u2019s also a social media aspect to this- you could create and share your own \u2018sonic maps\u2019 of your surroundings to experience the unique sonic landscapes that matter to your friends and family. </p></li>\n</ol>\n<p><strong>Why is ARound unique?</strong></p>\n<p>ARound brings a new perspective to the possibilities of Augmented Reality. While most of AR today is centered on augmenting one's visual systems, we think that there's immense unrealized potential in augmented one\u2019s sense of hearing. While current-generation AR systems can only augment your visuals in a tiny field of view, spatial audio enhances the user\u2019s perception in all 360 degrees. </p>\n<p>It takes advantage of the spatialization and contextualization abilities of AR technologies to create a highly responsive and immersive experience. With good computer vision and enough sound pins placed on the map, ARound could build a vibrant \u2018Internet of Sounds\u2019 - an immersive and contextual layer of sound augmented on top of the real world. </p>\n<h2><strong>Current features</strong></h2>\n<ol>\n<li><strong>Learn about their environment</strong></li>\n</ol>\n<p>As the users walk through the world, they\u2019ll become subtly aware of all the sounds and tagged objects around them. That\u2019s important for the blind - objects that are quiet are invisible, so augmented sounds help you orient yourself and learn about objects in your surroundings. Haptic feedback could make this useful for the deaf as well. That\u2019s also interesting to mainstream audiences as a discovery or educational platform. </p>\n<p><strong>2</strong><strong>. Path-finding and **</strong>_Deviation detection _**</p>\n<p>Easily find your way back on hikes and new paths. Hands-free and don\u2019t need to be looking at the screen, so you can navigate yourself which engaging with the real world. If you deviate too much from your path, the app will gently alert you of it, and guide you back in the correct direction. Since the deviation alert is volume-based, you always know exactly how far away you are from your path. </p>\n<p><strong>3</strong><strong>. **</strong><em>Social media</em>**</p>\n<p>Sonic scapes can be created and shared by all. Users can create sound maps for fellow travelers or teachers can make students discover cities and events. </p>\n<h2>*<em>What inspired us *</em></h2>\n<p>Independent living and traveling by people with disabilities have always been a challenge. This is especially true for the visually impaired population. Activities such as walking around or getting to familiar places like cafes, post office, ATM etc. can be challenging. Getting around unfamiliar routes while hiking, sailing or on nature walks can be be even more challenging. </p>\n<h2><strong>Challenges we ran into</strong></h2>\n<p>Designing for app for the blind presents a whole new set of design challenges, many of which we were initially unaware of. Sunish\u2019s experience in accessibility design was crucial in designing a product that would actually be usable by the target audience. However, we learned that the Unity engine was not natively compatible with Google Talkback and the other accessibility features on Android. The plugin to enable talkback was a paid feature, and under the licensing rules of the hackathon, using it would\u2019ve disqualified us. </p>\n<p>We also found out that our phones were not supported by the ARCore platform. Thanks to the ar-for-all guide, and the help of the mentors at the event, we finally managed to get it to work on (some of) our phones. </p>\n<h2>*<em>Accomplishments *</em></h2>\n<h2>We are thrilled to have built a working prototype. We were able to implement directional spatial audio that leads you along a certain path. We are proud about the idea being user-validated by our team member who is visually impaired.</h2>\n<h1><strong>What we learned</strong></h1>\n<p>None of us had a lot of prior experience with sound design or spatial audio, so we learned a lot about that. We got to play with ARCore and Firebase.  Some of us improved our understanding of how to work with Unity better. We brainstormed about translating user experience and feedback into technical solutions and that was extremely rewarding. We even learned how to incorporate accessibility/inclusivity design in our product. Our collaboration skills improved as well! </p>\n<p><strong>What's next for ARound</strong></p>\n<p>We are looking to develop our MVP into a full-scale platform that would help all our user types*  to navigate a given environment as well as be fun experience to use in everyday life. Finally, we want to build a full-scale platform for augmented sound, something like ARcore or ARkit, but with spatial direction in mind. With the help of this platform, many developers would be able to jump in and build all kinds of amazing apps and experiences. We are very excited for the future of ARound.</p>\n</div>",
    "content_md": "\n**ARound**\n\n\n**Augmented Reality app for sound-based navigation**\n\n\n**Team ARound**\n\n\nAnandana Kapur, Dhara Bhavsar, Maxym Nesmashny, Sunish Gupta, Vedant Saran\n\n\n**User types**\n\n\nVisually impaired (sound reliant)\n\n\nVisually and hearing impaired (haptic feedback reliant)\n\n\nMainstream (information and context reliant)\n\n\n**Why this app?**\n\n\nTeam **Getting ARound ** wants to augment the world with sound. Places of interest emit sounds that alert you of their presence, and that adds another layer of information to the world around us. \n\n\nSpatial audio and ASMR related sounds can help to augment our everyday experiences and be a very powerful tool to navigate the world. \n\n\nContextual audio cues that do not interfere with existing sounds or cause disorientation can be very valuable to navigate cities, forests, etc.\n\n\n**What does ARound do?**\n\n\nThe Augmented Reality app **ARound** equips all its users to independently navigate spaces by augmenting sounds of places, objects, and activities. In its current state the app functions using three modes:\n\n\n1. ***Discovery mode***: As you walk down a path, we use GPS data with combination of ARCore camera technology to sense your surroundings and trigger sounds of objects and locations on your path depending on your orientation towards them. The sounds are geofenced to an area so that they start playing just before you approach an object/place of interest, and gain in volume as you get closer.\n2. ***Breadcrumb mode***: As you walk around, the app leaves a trail of sound along the path you have taken. If you lose your way or need to retrace your steps, you can simply follow your \"audio breadcrumbs\" to follow the path you took. Since the sound is anchored to the real-world, and we can accurately track the user\u2019s position using ARCore, the sound is spatialized to the user\u2019s orientation relative to the breadcrumbs. That makes it super easy to get back on the path - you just follow the direction the sound appears to be coming from. This feature gives the visually impaired the freedom and confidence to go on walks, hikes, or boating, without assistance.\n3. ***Share mode***: You can choose sounds from a library of audio files and link them to locations in the real world, through a web application. This creates a sound pin on the map that is triggered when the user approaches that location in the real world. This could be used to set up meetings with a blind person - You\u2019d just drop a pin of an audio note at the meeting location, and they\u2019d know when they arrived. There\u2019s also a social media aspect to this- you could create and share your own \u2018sonic maps\u2019 of your surroundings to experience the unique sonic landscapes that matter to your friends and family.\n\n\n**Why is ARound unique?**\n\n\nARound brings a new perspective to the possibilities of Augmented Reality. While most of AR today is centered on augmenting one's visual systems, we think that there's immense unrealized potential in augmented one\u2019s sense of hearing. While current-generation AR systems can only augment your visuals in a tiny field of view, spatial audio enhances the user\u2019s perception in all 360 degrees. \n\n\nIt takes advantage of the spatialization and contextualization abilities of AR technologies to create a highly responsive and immersive experience. With good computer vision and enough sound pins placed on the map, ARound could build a vibrant \u2018Internet of Sounds\u2019 - an immersive and contextual layer of sound augmented on top of the real world. \n\n\n## **Current features**\n\n\n1. **Learn about their environment**\n\n\nAs the users walk through the world, they\u2019ll become subtly aware of all the sounds and tagged objects around them. That\u2019s important for the blind - objects that are quiet are invisible, so augmented sounds help you orient yourself and learn about objects in your surroundings. Haptic feedback could make this useful for the deaf as well. That\u2019s also interesting to mainstream audiences as a discovery or educational platform. \n\n\n**2****. Path-finding and ****\\_Deviation detection \\_**\n\n\nEasily find your way back on hikes and new paths. Hands-free and don\u2019t need to be looking at the screen, so you can navigate yourself which engaging with the real world. If you deviate too much from your path, the app will gently alert you of it, and guide you back in the correct direction. Since the deviation alert is volume-based, you always know exactly how far away you are from your path. \n\n\n**3****. *****Social media***\n\n\nSonic scapes can be created and shared by all. Users can create sound maps for fellow travelers or teachers can make students discover cities and events. \n\n\n## **What inspired us **\n\n\nIndependent living and traveling by people with disabilities have always been a challenge. This is especially true for the visually impaired population. Activities such as walking around or getting to familiar places like cafes, post office, ATM etc. can be challenging. Getting around unfamiliar routes while hiking, sailing or on nature walks can be be even more challenging. \n\n\n## **Challenges we ran into**\n\n\nDesigning for app for the blind presents a whole new set of design challenges, many of which we were initially unaware of. Sunish\u2019s experience in accessibility design was crucial in designing a product that would actually be usable by the target audience. However, we learned that the Unity engine was not natively compatible with Google Talkback and the other accessibility features on Android. The plugin to enable talkback was a paid feature, and under the licensing rules of the hackathon, using it would\u2019ve disqualified us. \n\n\nWe also found out that our phones were not supported by the ARCore platform. Thanks to the ar-for-all guide, and the help of the mentors at the event, we finally managed to get it to work on (some of) our phones. \n\n\n## **Accomplishments **\n\n\n## We are thrilled to have built a working prototype. We were able to implement directional spatial audio that leads you along a certain path. We are proud about the idea being user-validated by our team member who is visually impaired.\n\n\n# **What we learned**\n\n\nNone of us had a lot of prior experience with sound design or spatial audio, so we learned a lot about that. We got to play with ARCore and Firebase. Some of us improved our understanding of how to work with Unity better. We brainstormed about translating user experience and feedback into technical solutions and that was extremely rewarding. We even learned how to incorporate accessibility/inclusivity design in our product. Our collaboration skills improved as well! \n\n\n**What's next for ARound**\n\n\nWe are looking to develop our MVP into a full-scale platform that would help all our user types* to navigate a given environment as well as be fun experience to use in everyday life. Finally, we want to build a full-scale platform for augmented sound, something like ARcore or ARkit, but with spatial direction in mind. With the help of this platform, many developers would be able to jump in and build all kinds of amazing apps and experiences. We are very excited for the future of ARound.\n\n\n"
}