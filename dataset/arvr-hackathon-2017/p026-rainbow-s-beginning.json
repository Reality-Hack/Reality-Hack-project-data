{
    "source": "https://devpost.com/software/rainbow-s-beginning",
    "title": "Rainbow | Seamless Mixed Reality Begins Here",
    "blurb": "Rainbow organizes virtual information for real space through shareable mixed reality layers.",
    "awards": [],
    "videos": [
        "https://www.youtube.com/embed/HsBf6FyjB1I?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
    ],
    "images": [
        {
            "title": "Mixed Reality Network Diagram",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/546/717/datas/original.png"
        },
        {
            "title": "Circuit diagram for IOT with Arduino",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/546/757/datas/original.png"
        },
        {
            "title": "Logo",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/546/767/datas/original.png"
        }
    ],
    "team": [
        {
            "name": "Rogue Fong",
            "about": "I integrated the Arduino with Unity using serial communication, and programmed logic and functionality for the interactions. ",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/455/740/datas/profile.JPG"
        },
        {
            "name": "Adam Sauer",
            "about": "I set up the environment/scene in Unity, integrated Mapbox SDK with live traffic data and other UI layers, and set up Meta SDK with Hand tracking/UI interaction.",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/544/762/datas/profile.jpg"
        },
        {
            "name": "Doc Martens",
            "about": "I worked on U/X design, asset creation, pitch and demo video and built/coded all the Internet of things connections using Arduino and sensors.",
            "photo": "https://avatars1.githubusercontent.com/u/13619262?height=180&v=4&width=180"
        },
        {
            "name": "yunxin",
            "about": "",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/546/863/datas/profile.JPG"
        },
        {
            "name": "fpunjwani",
            "about": "",
            "photo": "https://avatars1.githubusercontent.com/u/22136612?height=180&v=4&width=180"
        }
    ],
    "built_with": [
        "arduino",
        "c#",
        "mapbox",
        "meta",
        "unity"
    ],
    "content_html": "<div>\n<h2>Inspiration</h2>\n<p>We already live in augmented reality. But the user experience is sorely lacking. In order to access information or connect with others virtually, we rely on smartphones, hiding behind our screens and disconnecting from the real world. We believe that accessing virtual information should be effortless, allowing us to interact naturally with the world around us. As A/R technology improves, this reality is moving closer and closer. But how might we ensure that today's information overload doesn't pollute our physical reality? How do we maintain what is true and what is real in a landscape of ubiquitous digital augmentation? To begin to answer these questions we created Rainbow, a design pattern for shareable mixed reality.</p>\n<h2>What it does</h2>\n<p>Rainbow is an A/R solution for organizing virtual information in real spaces. By collecting digital content into layers, Rainbow helps users navigate between several different augmented experiences for one location. </p>\n<p><strong>User Scenario</strong> \nIf Ben needed to get to the T Station today, he\u2019d have to take out his phone, find the right app, get directions, and keeps his nose pressed to the screen while mentally navigating between the image on his phone and world around him. He\u2019d have to switch apps to check the train schedule or see if there might be a better transit option.\nBut with Rainbow, Ben could simply turn on the City Layer published by the municipal government, containing all the transit and tourist information he would need to navigate the space. This information would sync up with actual landmarks and transit hubs, providing a contextual navigation experience that makes sense. If he needed to interact with other information around him, he could easily switch the layer in his A/R headset.</p>\n<p><strong>What is layerable reality?</strong>\nLayers of mixed and augmented reality that can be programmed separately. They act as a virtual layer over a physical space, harnessing web APIs, geo-location, and local IOT devices to enhance one or more objects in that space with virtual elements. </p>\n<ul>\n<li>One space can have many Layers. </li>\n<li>Unless programmed specifically, only one pLayer can be viewed by one person at one time. </li>\n<li>Each Layer has several types of rights: content-production and delivery, interactivity, purchasing, editing, administration etc.</li>\n<li>Layers can be owned and controlled by private companies/ventures, individuals, governments or NGOs. </li>\n<li>There can also be common Layers, virtual layers where any user can freely edit, add, subtract, or content or interactivity. Typically these sandbox type layers are controlled through a distributed form of moderation and governance, although anarcho-varieties can exist as well.</li>\n</ul>\n<p><strong>Examples of Layer Types</strong></p>\n<ul>\n<li>Public Layer: Controlled by a municipal government. Provides basic directions to subways, common attractions, public bathrooms, and interactivity with municipal data streams (311, 911 etc.).</li>\n<li>Public/Private Layer owned: Controlled by local Kendall Square district. Provides information about local businesses (promotions, coupons, hours of operation) and events happening in the area</li>\n<li>Private Layer owned by MIT: Controlled privately by a local university. This layer can include tips/tricks from MIT students about places, restaurants etc. This pLayer can have separate sub-layers that allow for ad-hoc group communication, private messaging, urban gaming etc.</li>\n<li>Pop-up Layer: Controlled privately and temporarily by Blizzard Entertainment. A temporary (\u2018pop-up\u2019) pLayer for an urban gaming experience for users subscribed to Blizzard\u2019s World of Warcraft</li>\n</ul>\n<h2>How we built it</h2>\n<p>Rainbow was built using mixed reality technology, Mapbox, and Unity, for Meta\u2019s mixed reality technology. For our prototype, we built an experience that allows users to see different views of an IOT devices recording environmental information and providing an NFC login panel for Kendall Square in Cambridge, MA. The user is able to access two layers of reality: the first one being \u2018municipal\u2019, with weather information streaming from the sensors and the second one being \u2018game\u2019, with a specific event that only select users can access through the NFC.</p>\n<p>First, Rainbow required an understanding of our physical space. We then combined this with geolocation and mapbox to map out space in Unity, including specific markers for smart objects\nSecond, we create a smart object, an internet-of-things box, that shows multiple type of information. What information the user views is dependent on the layer the user is in.\nThird, we built two layers: a Municipal Layer and a Game Layer\nFor the Municipal Layer, we used real-time weather information to share visually with the user. We created a smart box that works with Arduino to get real-time temperature and humidity information as well as the log-in state of unique NFC chips. This information is then threaded into Unity and can be interacted with in A/R.</p>\n<p>For the Game Layer, we created an experience, unlocked only once a specific number of users sign in. We used RFID sensors o that can be accessed by select users\nFinally, we created seamless switching between layers using C# in Unity as well as icons and the user interface using Adobe Illustrator.</p>\n<h2>Challenges we ran into</h2>\n<p>Familiarizing ourselves with all the VR/AR hardwares and using them to create great mixed reality experiences was challenging, but in the end everything worked out well.\nCreating a believable and powerful demo that captures the product features precisely was hard.</p>\n<h2>Accomplishments that we're proud of</h2>\n<p>We are most proud that we can envision a seamlessly mixed reality infrastructure using Meta Vision and Mapbox while implementing IoT devices and blockchain concepts in especially such a short time. Our team members have a background in design, engineering, and business, and all firmly believe in a future where mixed reality would generate more personalized daily experiences and genuine social connections. \nIn two days, we have tested various sensors, experimented with Microsoft HoloLens, Meta Vision, and various geospatial mapping tools to bring on the best-mixed reality experience. It took us a while to figure out all the hardware settings, but it worked out well!\nWe are also proud of the support and trust within our team. From the very start, we\u2019ve set our goal to build an awesome product and to challenge ourselves. And we are so proud we\u2019ve done it!</p>\n<h2>What's next for Rainbow's Beginning</h2>\n<p>With Rainbow, we are the creating infrastructure for ubiquitous augmented reality using the Internet of Things, an infrastructure that enables seamless mixed reality experience. </p>\n<p><strong>Our top priorities include:</strong>\n*Pushing feasibility</p>\n<ul>\n<li>How can users interact with each other in mixed reality?</li>\n<li>How do permissions (read, write access) works in different Layers?</li>\n<li>How might we integrate blockchain for user identification and authentication and/or registering digital asset intellectual property?</li>\n<li>How might integrate with other connected devices and enable devices to get smart in the city?\n** Further testing desirability and viability **</li>\n<li>How do different users interact with spaces in mixed reality?</li>\n<li>What does a revenue generation model?</li>\n<li>How can we scale our idea through leveraging the existing ecosystem?</li>\n</ul>\n</div>",
    "content_md": "\n## Inspiration\n\n\nWe already live in augmented reality. But the user experience is sorely lacking. In order to access information or connect with others virtually, we rely on smartphones, hiding behind our screens and disconnecting from the real world. We believe that accessing virtual information should be effortless, allowing us to interact naturally with the world around us. As A/R technology improves, this reality is moving closer and closer. But how might we ensure that today's information overload doesn't pollute our physical reality? How do we maintain what is true and what is real in a landscape of ubiquitous digital augmentation? To begin to answer these questions we created Rainbow, a design pattern for shareable mixed reality.\n\n\n## What it does\n\n\nRainbow is an A/R solution for organizing virtual information in real spaces. By collecting digital content into layers, Rainbow helps users navigate between several different augmented experiences for one location. \n\n\n**User Scenario** \nIf Ben needed to get to the T Station today, he\u2019d have to take out his phone, find the right app, get directions, and keeps his nose pressed to the screen while mentally navigating between the image on his phone and world around him. He\u2019d have to switch apps to check the train schedule or see if there might be a better transit option.\nBut with Rainbow, Ben could simply turn on the City Layer published by the municipal government, containing all the transit and tourist information he would need to navigate the space. This information would sync up with actual landmarks and transit hubs, providing a contextual navigation experience that makes sense. If he needed to interact with other information around him, he could easily switch the layer in his A/R headset.\n\n\n**What is layerable reality?**\nLayers of mixed and augmented reality that can be programmed separately. They act as a virtual layer over a physical space, harnessing web APIs, geo-location, and local IOT devices to enhance one or more objects in that space with virtual elements. \n\n\n* One space can have many Layers.\n* Unless programmed specifically, only one pLayer can be viewed by one person at one time.\n* Each Layer has several types of rights: content-production and delivery, interactivity, purchasing, editing, administration etc.\n* Layers can be owned and controlled by private companies/ventures, individuals, governments or NGOs.\n* There can also be common Layers, virtual layers where any user can freely edit, add, subtract, or content or interactivity. Typically these sandbox type layers are controlled through a distributed form of moderation and governance, although anarcho-varieties can exist as well.\n\n\n**Examples of Layer Types**\n\n\n* Public Layer: Controlled by a municipal government. Provides basic directions to subways, common attractions, public bathrooms, and interactivity with municipal data streams (311, 911 etc.).\n* Public/Private Layer owned: Controlled by local Kendall Square district. Provides information about local businesses (promotions, coupons, hours of operation) and events happening in the area\n* Private Layer owned by MIT: Controlled privately by a local university. This layer can include tips/tricks from MIT students about places, restaurants etc. This pLayer can have separate sub-layers that allow for ad-hoc group communication, private messaging, urban gaming etc.\n* Pop-up Layer: Controlled privately and temporarily by Blizzard Entertainment. A temporary (\u2018pop-up\u2019) pLayer for an urban gaming experience for users subscribed to Blizzard\u2019s World of Warcraft\n\n\n## How we built it\n\n\nRainbow was built using mixed reality technology, Mapbox, and Unity, for Meta\u2019s mixed reality technology. For our prototype, we built an experience that allows users to see different views of an IOT devices recording environmental information and providing an NFC login panel for Kendall Square in Cambridge, MA. The user is able to access two layers of reality: the first one being \u2018municipal\u2019, with weather information streaming from the sensors and the second one being \u2018game\u2019, with a specific event that only select users can access through the NFC.\n\n\nFirst, Rainbow required an understanding of our physical space. We then combined this with geolocation and mapbox to map out space in Unity, including specific markers for smart objects\nSecond, we create a smart object, an internet-of-things box, that shows multiple type of information. What information the user views is dependent on the layer the user is in.\nThird, we built two layers: a Municipal Layer and a Game Layer\nFor the Municipal Layer, we used real-time weather information to share visually with the user. We created a smart box that works with Arduino to get real-time temperature and humidity information as well as the log-in state of unique NFC chips. This information is then threaded into Unity and can be interacted with in A/R.\n\n\nFor the Game Layer, we created an experience, unlocked only once a specific number of users sign in. We used RFID sensors o that can be accessed by select users\nFinally, we created seamless switching between layers using C# in Unity as well as icons and the user interface using Adobe Illustrator.\n\n\n## Challenges we ran into\n\n\nFamiliarizing ourselves with all the VR/AR hardwares and using them to create great mixed reality experiences was challenging, but in the end everything worked out well.\nCreating a believable and powerful demo that captures the product features precisely was hard.\n\n\n## Accomplishments that we're proud of\n\n\nWe are most proud that we can envision a seamlessly mixed reality infrastructure using Meta Vision and Mapbox while implementing IoT devices and blockchain concepts in especially such a short time. Our team members have a background in design, engineering, and business, and all firmly believe in a future where mixed reality would generate more personalized daily experiences and genuine social connections. \nIn two days, we have tested various sensors, experimented with Microsoft HoloLens, Meta Vision, and various geospatial mapping tools to bring on the best-mixed reality experience. It took us a while to figure out all the hardware settings, but it worked out well!\nWe are also proud of the support and trust within our team. From the very start, we\u2019ve set our goal to build an awesome product and to challenge ourselves. And we are so proud we\u2019ve done it!\n\n\n## What's next for Rainbow's Beginning\n\n\nWith Rainbow, we are the creating infrastructure for ubiquitous augmented reality using the Internet of Things, an infrastructure that enables seamless mixed reality experience. \n\n\n**Our top priorities include:**\n*Pushing feasibility\n\n\n* How can users interact with each other in mixed reality?\n* How do permissions (read, write access) works in different Layers?\n* How might we integrate blockchain for user identification and authentication and/or registering digital asset intellectual property?\n* How might integrate with other connected devices and enable devices to get smart in the city?\n** Further testing desirability and viability **\n* How do different users interact with spaces in mixed reality?\n* What does a revenue generation model?\n* How can we scale our idea through leveraging the existing ecosystem?\n\n\n"
}