{
    "source": "https://devpost.com/software/ecstasis",
    "title": "Ecstasis",
    "blurb": "Through AR and VR, Ecstasis reinforces social connection between therapists and patients under palliative and hospice care.",
    "awards": [],
    "videos": [
        "https://www.youtube.com/embed/i3d5ENwf5cE?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
    ],
    "images": [],
    "team": [
        {
            "name": "Peter Iordanov",
            "about": "I setup and built the UI on the Project North Star headset, and wrote scripts to map animations to be controlled by Leap Motion UI elements",
            "photo": "https://avatars.githubusercontent.com/u/5401480?height=180&v=3&width=180"
        },
        {
            "name": "Ryan Weatherby",
            "about": "Visual design and conceptualization - auxiliary motion graphics",
            "photo": "https://media-exp1.licdn.com/dms/image/C5603AQHoz5pxKuIHlw/profile-displayphoto-shrink_800_800/0?e=1585180800&height=180&t=Bqp8SMaNe7EskYqJonuDvl7sRE6sxveX1ZNipIQ2mUE&v=beta&width=180"
        },
        {
            "name": "Mike Dopsa",
            "about": "3D Modeling, Animation and sound design. \nAR and VR experience design, Programming for networking & Holographic Sensors.",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/748/719/datas/profile.jpg"
        },
        {
            "name": "masternader",
            "about": "",
            "photo": "https://avatars2.githubusercontent.com/u/41163985?height=180&v=4&width=180"
        },
        {
            "name": "Simi Shenoy",
            "about": "",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/917/272/datas/profile.jpg"
        }
    ],
    "built_with": [
        "google-poly",
        "leap-motion",
        "maya",
        "normcore",
        "oculus",
        "project-north-star",
        "real-sense",
        "rhinoceros",
        "steam",
        "tiltbrush",
        "unity"
    ],
    "content_html": "<div>\n<h2>Problem</h2>\n<p>According to WHO, each year an estimated 40 million people are in need of palliative and hospice care. The global need for this type of care will continue to grow as a result of the rising burden of noncommunicable diseases and ageing populations. Early palliative and hospice care reduces unnecessary hospital admissions and the use of health services. </p>\n<p>Palliative and hospice care refer to an interdisciplinary medical care-giving approach aimed at optimizing quality of life, mitigating suffering from the stress of terminal illness and providing comfort and care to patients and their families to acceptance and undergo a transformation of perception. </p>\n<p>Virtual Embodiment has been proven to be an effective clinical and therapeutic application of virtual reality as a therapy (Bourdin, P. 2017). But therein lies a problem: virtualization of patients by therapists using head-mounted virtual reality devices effectively diminishes the social connection between them. The strong bonds therapists spend months developing with their patients becomes threatened by a new care paradigm that deemphasizes human interaction in favor of \u201cdosed\u201d or \u201cautoplay\u201d therapy.</p>\n<p>More information on palliative care and its dynamic socio-economic challenges can be found here: <a href=\"https://www.who.int/news-room/fact-sheets/detail/palliative-care\" rel=\"nofollow\">https://www.who.int/news-room/fact-sheets/detail/palliative-care</a></p>\n<h2>Solution</h2>\n<p>Virtual reality (VR) and virtual embodiment (VE) have been demonstrated to be therapeutically effective tools for helping to cope with the reality of transitional palliative and hospice care (Bourdin, P. 2017). Current clinical therapy standards are confined to mainly provide relief by sedation, rarely indicating more access to support groups and professionals should the patient request it. Effective therapies for near end of life patients have been narrowing drastically. Virtual Reality and Virtual Embodiment provides a powerful vehicle for the transition into hospice care through immersion, the therapeutically viable engine that drives the heart of a convincing VR experience.</p>\n<p>Ecstasis (to be or stand outside oneself, a removal to elsewhere) is an immersive VR journey that reconnects the relationship between therapist and patient and reduces stress of patients in need of palliative care allowing them to cope with their illnesses with a more positive mindset.</p>\n<p>Based on a white paper that studies how \"fear of death was found to be lower in the experimental group that underwent virtual out-of-body experiences\" (OBE) (Bourdin,1), Ecstasis was designed as an OBE generator controlled by trusted therapists that would personalize the experience based on the patient\u2019s biofeedback.   </p>\n<p>Bourdin, P., Barberia, I., Oliva, R. and Slater, M. (2017). A Virtual Out-of-Body Experience Reduces Fear of Death.</p>\n<h2>What it does</h2>\n<p>Therapist takes a patient on a real-time immersive and responsive journey in VR. The clinician has access to a hand\u2019s free control system UI that allows them to set the environment, control movement and embody various digital assets to further enhance the relationship between therapist and patient. The intent of the experience is to take the patient on an immersive journey that results in an out of body (OBE) experience. It is through these immersive journeys, personally tailored by the therapist based on each patients care needs. \nThe therapist\u2019s digital avatar accompanies the patient in their immersive VR journey. At the very end of the experience, the patient is put in a virtual out of body experience.\nCareful consideration of biometric feedback will allow the therapist to disseminate the OBE with maximum effectiveness because it will be synchronized to the exact moment that patient proprioception has been primed for the OBE.\nEcstasis creates an increasingly immersive cascade of visuotactile techniques that are injected into the experience and controlled by the clinician in real-time based on analysis of biomarkers that indicate \u201creadiness\u201d, what we call the subjects suggestibility for the therapy. \nOnce a patient is qualified to be a suitable candidate for VR therapy, a licensed therapist from the hospice care team will work closely with the patient to enable a custom virtual out of body experience (VOBE)\nVR Therapy is effective, however, there tends to be a sense of isolation, especially in a therapeutic context. Ecstasis restores experience of guided therapy by allowing the therapist to read the patient while controlling the immersive VR experience in real time while encouraging the therapists engagement in real time. An OBE is created by a systematic manipulation of audiovisual cues to elicit \u201cavatarization\u201d the embodiment of patient into our digital model by giving them full control over this new avatar.</p>\n<h2>How we built it</h2>\n<p>We built this in two parts, a VR application with the Oculus Quest and an AR component using Project North Star headset.</p>\n<p>We setup a Project North Star headset with an Intel Real Sense for 6DOF tracking and a Leap Motion for hand tracking, and created a movable user interface to control the state of the VR experience. This interface would then translate into controlling the flow of the experience, such as triggering the out of body experience or slowing down the experience for the user.</p>\n<h2>Challenges we ran into</h2>\n<p>We first tried to set up the North Star headset using the newly released SteamVR drivers and use a Vive tracker to track head position. This proved to be very difficult, with problems arising from the tracker\u2019s transform being off as well as SteamVR failing to build on our computer. We eventually switched to the RealSense camera which took us only a half hour of setup and worked wonderfully.</p>\n<p>Triggering animations based on Leap Motion APIs proved difficult. We tried to use the Doozy UI library to help configure these actions, but we unable to install the Unity Package along with Leap Motion plugin. We resolved this by writing code to sync the animations with the Leap Motion\u2019s Slider state. We synced it between both the elements in the project and across the network using the NormalCore library. </p>\n<p>Another problem we faced was integrating both headsets into the same Unity project. We had gotten NormCore to create a full multiplayer environment but once we added the other headset package it fell apart. We ran into this too soon to the deadline and left us without being able to demonstrate the two parts working in tandem.</p>\n<h2>Accomplishments that we're proud of</h2>\n<p>We are proud of having one of only two working North Star project headsets at the hackathon and took on the incredibly daunting task of integrating this already prototypical headset into a scene with a VR device. We also helped give input to both the newly released SteamVR plugin for North Star and the NormalAPI, which will help both of the projects mature in the future.</p>\n<h2>What we learned</h2>\n<p>We learned how to develop on the Project North Star as well as working with the SDKs of RealSense, Leap Motion, and SteamVR. We learned many teamwork skills to break down and prioritize our tasks and design what interactions we would create, both physically and virtually.</p>\n<h2>Citations</h2>\n<p>Nhpco.org. (2019). NHPCO Facts Figures. [online] Available at: <a href=\"https://www.nhpco.org/wp-content/uploads/2019/07/2018_NHPCO_Facts_Figures.pdf\" rel=\"nofollow\">https://www.nhpco.org/wp-content/uploads/2019/07/2018_NHPCO_Facts_Figures.pdf</a> [Accessed 19 Jan. 2020].</p>\n<p>Bourdin, P., Barberia, I., Oliva, R. and Slater, M. (2017). A Virtual Out-of-Body Experience Reduces Fear of Death.</p>\n</div>",
    "content_md": "\n## Problem\n\n\nAccording to WHO, each year an estimated 40 million people are in need of palliative and hospice care. The global need for this type of care will continue to grow as a result of the rising burden of noncommunicable diseases and ageing populations. Early palliative and hospice care reduces unnecessary hospital admissions and the use of health services. \n\n\nPalliative and hospice care refer to an interdisciplinary medical care-giving approach aimed at optimizing quality of life, mitigating suffering from the stress of terminal illness and providing comfort and care to patients and their families to acceptance and undergo a transformation of perception. \n\n\nVirtual Embodiment has been proven to be an effective clinical and therapeutic application of virtual reality as a therapy (Bourdin, P. 2017). But therein lies a problem: virtualization of patients by therapists using head-mounted virtual reality devices effectively diminishes the social connection between them. The strong bonds therapists spend months developing with their patients becomes threatened by a new care paradigm that deemphasizes human interaction in favor of \u201cdosed\u201d or \u201cautoplay\u201d therapy.\n\n\nMore information on palliative care and its dynamic socio-economic challenges can be found here: <https://www.who.int/news-room/fact-sheets/detail/palliative-care>\n\n\n## Solution\n\n\nVirtual reality (VR) and virtual embodiment (VE) have been demonstrated to be therapeutically effective tools for helping to cope with the reality of transitional palliative and hospice care (Bourdin, P. 2017). Current clinical therapy standards are confined to mainly provide relief by sedation, rarely indicating more access to support groups and professionals should the patient request it. Effective therapies for near end of life patients have been narrowing drastically. Virtual Reality and Virtual Embodiment provides a powerful vehicle for the transition into hospice care through immersion, the therapeutically viable engine that drives the heart of a convincing VR experience.\n\n\nEcstasis (to be or stand outside oneself, a removal to elsewhere) is an immersive VR journey that reconnects the relationship between therapist and patient and reduces stress of patients in need of palliative care allowing them to cope with their illnesses with a more positive mindset.\n\n\nBased on a white paper that studies how \"fear of death was found to be lower in the experimental group that underwent virtual out-of-body experiences\" (OBE) (Bourdin,1), Ecstasis was designed as an OBE generator controlled by trusted therapists that would personalize the experience based on the patient\u2019s biofeedback. \n\n\nBourdin, P., Barberia, I., Oliva, R. and Slater, M. (2017). A Virtual Out-of-Body Experience Reduces Fear of Death.\n\n\n## What it does\n\n\nTherapist takes a patient on a real-time immersive and responsive journey in VR. The clinician has access to a hand\u2019s free control system UI that allows them to set the environment, control movement and embody various digital assets to further enhance the relationship between therapist and patient. The intent of the experience is to take the patient on an immersive journey that results in an out of body (OBE) experience. It is through these immersive journeys, personally tailored by the therapist based on each patients care needs. \nThe therapist\u2019s digital avatar accompanies the patient in their immersive VR journey. At the very end of the experience, the patient is put in a virtual out of body experience.\nCareful consideration of biometric feedback will allow the therapist to disseminate the OBE with maximum effectiveness because it will be synchronized to the exact moment that patient proprioception has been primed for the OBE.\nEcstasis creates an increasingly immersive cascade of visuotactile techniques that are injected into the experience and controlled by the clinician in real-time based on analysis of biomarkers that indicate \u201creadiness\u201d, what we call the subjects suggestibility for the therapy. \nOnce a patient is qualified to be a suitable candidate for VR therapy, a licensed therapist from the hospice care team will work closely with the patient to enable a custom virtual out of body experience (VOBE)\nVR Therapy is effective, however, there tends to be a sense of isolation, especially in a therapeutic context. Ecstasis restores experience of guided therapy by allowing the therapist to read the patient while controlling the immersive VR experience in real time while encouraging the therapists engagement in real time. An OBE is created by a systematic manipulation of audiovisual cues to elicit \u201cavatarization\u201d the embodiment of patient into our digital model by giving them full control over this new avatar.\n\n\n## How we built it\n\n\nWe built this in two parts, a VR application with the Oculus Quest and an AR component using Project North Star headset.\n\n\nWe setup a Project North Star headset with an Intel Real Sense for 6DOF tracking and a Leap Motion for hand tracking, and created a movable user interface to control the state of the VR experience. This interface would then translate into controlling the flow of the experience, such as triggering the out of body experience or slowing down the experience for the user.\n\n\n## Challenges we ran into\n\n\nWe first tried to set up the North Star headset using the newly released SteamVR drivers and use a Vive tracker to track head position. This proved to be very difficult, with problems arising from the tracker\u2019s transform being off as well as SteamVR failing to build on our computer. We eventually switched to the RealSense camera which took us only a half hour of setup and worked wonderfully.\n\n\nTriggering animations based on Leap Motion APIs proved difficult. We tried to use the Doozy UI library to help configure these actions, but we unable to install the Unity Package along with Leap Motion plugin. We resolved this by writing code to sync the animations with the Leap Motion\u2019s Slider state. We synced it between both the elements in the project and across the network using the NormalCore library. \n\n\nAnother problem we faced was integrating both headsets into the same Unity project. We had gotten NormCore to create a full multiplayer environment but once we added the other headset package it fell apart. We ran into this too soon to the deadline and left us without being able to demonstrate the two parts working in tandem.\n\n\n## Accomplishments that we're proud of\n\n\nWe are proud of having one of only two working North Star project headsets at the hackathon and took on the incredibly daunting task of integrating this already prototypical headset into a scene with a VR device. We also helped give input to both the newly released SteamVR plugin for North Star and the NormalAPI, which will help both of the projects mature in the future.\n\n\n## What we learned\n\n\nWe learned how to develop on the Project North Star as well as working with the SDKs of RealSense, Leap Motion, and SteamVR. We learned many teamwork skills to break down and prioritize our tasks and design what interactions we would create, both physically and virtually.\n\n\n## Citations\n\n\nNhpco.org. (2019). NHPCO Facts Figures. [online] Available at: <https://www.nhpco.org/wp-content/uploads/2019/07/2018_NHPCO_Facts_Figures.pdf> [Accessed 19 Jan. 2020].\n\n\nBourdin, P., Barberia, I., Oliva, R. and Slater, M. (2017). A Virtual Out-of-Body Experience Reduces Fear of Death.\n\n\n"
}