{
    "source": "https://devpost.com/software/youtopian",
    "title": "YOUtopia",
    "blurb": "The future powered by your mind",
    "awards": [],
    "videos": [
        "https://www.youtube.com/embed/AkBptwuxxwE?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
    ],
    "images": [
        {
            "title": "User testing",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/917/233/datas/original.png"
        },
        {
            "title": "outside town",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/917/231/datas/original.png"
        },
        {
            "title": "inner world",
            "src": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/000/917/232/datas/original.png"
        }
    ],
    "team": [
        {
            "name": "Wanyue Wang",
            "about": "I worked on collecting EEG data from headset and processing EEG data by Python and unity. Co-designed the concept and experience flow.",
            "photo": "https://www.gravatar.com/avatar/e61dfa076bdf072fda17349132e12051?d=https%3A%2F%2Fdevpost-challengepost.netdna-ssl.com%2Fassets%2Fdefaults%2Fno-avatar-180.png&s=180"
        },
        {
            "name": "Chuyi Wu",
            "about": "I mainly programmed Unity Script for the data-generative visual effects, and the trigger system, and merged the pieces in Unity project.\nI also co-designed and defined the concept and narrative experience flow.",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/914/610/datas/profile.jpg"
        },
        {
            "name": "Tina Chen",
            "about": "I worked on creative thinking, idea generating and help with 3D modeling in Unity. I came up with the user journey map and do the graphic design of our project logo and wrap up our idea in the intro video.",
            "photo": "https://www.gravatar.com/avatar/a8e1f8aff6f78383716bad1151f7fd40?d=https%3A%2F%2Fdevpost-challengepost.netdna-ssl.com%2Fassets%2Fdefaults%2Fno-avatar-180.png&s=180"
        },
        {
            "name": "Yangli Liu",
            "about": "I mainly worked on visual design, building 3D assets and unity set up (including lighting, sound, animation and teleportation). I also managed the project timeline and kept an eye on any post for our team.",
            "photo": "https://www.gravatar.com/avatar/10a10f8eaa149decf69e9dab979880a7?d=https%3A%2F%2Fdevpost-challengepost.netdna-ssl.com%2Fassets%2Fdefaults%2Fno-avatar-180.png&s=180"
        }
    ],
    "built_with": [
        "emotiv",
        "oculus",
        "python",
        "unity"
    ],
    "content_html": "<div>\n<h2>Inspiration</h2>\n<p>Our team is interested in people's emotions and how these emotions can impact our world. Therefore, we decided to let users see their inner energy. We transform EEG detecting data to the variation which would change the color, light, shape even the type of the city that users can see in VR. Utopia should be the world that can be customized by every unique individual, with their mind power. So, we say that future should be YOUtopia.</p>\n<h2>What it does</h2>\n<p>Experience the world created by your mind and interact with it.</p>\n<p>First, a short intro animation takes you into the experience and you will see a fantasy world based on reality. You can explore the environment on your own and find an entry to your utopia, during which your EEG data will be recorded. When you find the entry, you can explore a unique utopian world generated by your EEG that reflects your mindset. </p>\n<h2>How we built it</h2>\n<p>Our team started with a brainstorming about how the future world would look like, and how everyone's emotions or mindset can impact the future. Based on our idea, we created a simple user journey and a narrative brief to guide our later development.</p>\n<ul>\n<li>Unity (VR development)</li>\n<li>Emotiv Epoc+ EEG headset (EEG data collection)</li>\n<li>Python (Read EEG data from headset and process data)</li>\n<li>Oculus Rift</li>\n<li>Tilt Brush (3D modeling)</li>\n<li>Google Block (3D modeling)</li>\n<li>Free sound resource (background music)</li>\n</ul>\n<h2>Challenges we ran into</h2>\n<p>Everyone has a totally different opinion about the world, especially the future world. We tried to design an experience that is personalized for everyone. So the biggest challenge is how to create a generative world that represents the YOUtopian. We spent lots of time researching on several different visual styles and implement methods. Due to time limitation, we chose a mixed cyberpunk and authentic style to represent the \"current world\" and the \"future world\". We modeled most of assets by Tilt Brush. (There are still many things to improve.)</p>\n<p>Making use of EEG data is also challenging, because the it takes in data with various time gap (1-10s). EEG was also new to us, we spent time understanding the data format that EEG headset provides and how to integrate it into Unity development. We also tried to understand the meaning of those data, and develop a story with visual effects. Due to the lack of experienced Unity developer, we had a long scripting learning curve to creative generative art.</p>\n<p>Working with different VR SDKs is frustrated for us, we encountered many unexpected bugs due to unknown reasons.</p>\n<h2>Accomplishments that we're proud of</h2>\n<p>We successfully parse the data and wrote our own script to generative smooth animation. We also built a visually pleasing and exciting VR environment for audience to explore around with teleportation. The whole journey and narrative experience is simple but poetic and procedural. Although we worked on different assets individually, the end result is very aesthetically consistent.</p>\n<h2>What we learned</h2>\n<ul>\n<li>Work with Unity and changing data.</li>\n<li>Understand a bit more about EEG data.</li>\n<li>Team cooperation</li>\n</ul>\n<h2>What's next for YOUtopian</h2>\n<p>We the experience can be more unique for different people. It would be better if we can make more generative shapes for interactions with a more accurate EEG sensor.</p>\n</div>",
    "content_md": "\n## Inspiration\n\n\nOur team is interested in people's emotions and how these emotions can impact our world. Therefore, we decided to let users see their inner energy. We transform EEG detecting data to the variation which would change the color, light, shape even the type of the city that users can see in VR. Utopia should be the world that can be customized by every unique individual, with their mind power. So, we say that future should be YOUtopia.\n\n\n## What it does\n\n\nExperience the world created by your mind and interact with it.\n\n\nFirst, a short intro animation takes you into the experience and you will see a fantasy world based on reality. You can explore the environment on your own and find an entry to your utopia, during which your EEG data will be recorded. When you find the entry, you can explore a unique utopian world generated by your EEG that reflects your mindset. \n\n\n## How we built it\n\n\nOur team started with a brainstorming about how the future world would look like, and how everyone's emotions or mindset can impact the future. Based on our idea, we created a simple user journey and a narrative brief to guide our later development.\n\n\n* Unity (VR development)\n* Emotiv Epoc+ EEG headset (EEG data collection)\n* Python (Read EEG data from headset and process data)\n* Oculus Rift\n* Tilt Brush (3D modeling)\n* Google Block (3D modeling)\n* Free sound resource (background music)\n\n\n## Challenges we ran into\n\n\nEveryone has a totally different opinion about the world, especially the future world. We tried to design an experience that is personalized for everyone. So the biggest challenge is how to create a generative world that represents the YOUtopian. We spent lots of time researching on several different visual styles and implement methods. Due to time limitation, we chose a mixed cyberpunk and authentic style to represent the \"current world\" and the \"future world\". We modeled most of assets by Tilt Brush. (There are still many things to improve.)\n\n\nMaking use of EEG data is also challenging, because the it takes in data with various time gap (1-10s). EEG was also new to us, we spent time understanding the data format that EEG headset provides and how to integrate it into Unity development. We also tried to understand the meaning of those data, and develop a story with visual effects. Due to the lack of experienced Unity developer, we had a long scripting learning curve to creative generative art.\n\n\nWorking with different VR SDKs is frustrated for us, we encountered many unexpected bugs due to unknown reasons.\n\n\n## Accomplishments that we're proud of\n\n\nWe successfully parse the data and wrote our own script to generative smooth animation. We also built a visually pleasing and exciting VR environment for audience to explore around with teleportation. The whole journey and narrative experience is simple but poetic and procedural. Although we worked on different assets individually, the end result is very aesthetically consistent.\n\n\n## What we learned\n\n\n* Work with Unity and changing data.\n* Understand a bit more about EEG data.\n* Team cooperation\n\n\n## What's next for YOUtopian\n\n\nWe the experience can be more unique for different people. It would be better if we can make more generative shapes for interactions with a more accurate EEG sensor.\n\n\n"
}