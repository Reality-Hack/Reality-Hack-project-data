{
    "source": "https://devpost.com/software/clear-sight-zgrb7v",
    "title": "cleAR sight",
    "blurb": "A magic leap AR accessibility application for individuals with low vision",
    "awards": [
        "Best use of Magic Leap",
        "Wayfair's Way-more"
    ],
    "videos": [
        "https://www.youtube.com/embed/jcAOVeejTWc?enablejsapi=1&hl=en_US&rel=0&start=&version=3&wmode=transparent"
    ],
    "images": [],
    "team": [
        {
            "name": "Mike Dopsa",
            "about": "Concept & Technical Designer, User Flow, Sightless Interface Design, Video Producer, Voice Over Artist, BTS Documentation",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/748/719/datas/profile.jpg"
        },
        {
            "name": "Keith Bradley",
            "about": "Low Vision and Accessibility standards, 3D models, Audio Engineering, UX.",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/424/101/datas/profile.jpg"
        },
        {
            "name": "Media Ridha",
            "about": "",
            "photo": "https://graph.facebook.com/10104283282534841/picture?height=180&width=180"
        },
        {
            "name": "BXB2",
            "about": "",
            "photo": "https://avatars2.githubusercontent.com/u/34118361?height=180&v=4&width=180"
        },
        {
            "name": "Peter Lu",
            "about": "",
            "photo": "//challengepost-s3-challengepost.netdna-ssl.com/photos/production/user_photos/000/683/122/datas/profile.jpg"
        }
    ],
    "built_with": [
        "magicleap",
        "unity"
    ],
    "content_html": "<div>\n<h2>Inspiration</h2>\n<p>According to the National Center for Health Statistics, 26 Million Americans Adults experience significant vision loss, creating challenges with Depth Perception, Low-Light scenarios and proprioception. CleARsight for Magic Leap is a Spatial Computing Accessibility application, to improve the daily lives of individuals with Low Vision. </p>\n<h2>What it does</h2>\n<p>Using Magic Leap\u2019s World Mapping, Haptic Feedback, Spatial Audio, and Holographic Visual Overlay, CleARsight illuminates your environment, outlining object edges with High Contrast colours, and highlighting horizontal planes with a vivid pattern. </p>\n<p>Pulling the trigger of the 6DoF Controller, activates the environmental awareness system \u2018virtual cane.\u2019 Measuring the distance between the Controller, and the spatial mesh generated by the magic leap\u2019s world reconstruction system, Haptic feedback increases in intensity as obstacles get closer. Like the use of echo-location in nature, this allows the CleARsight wearer to gain a spatial understanding of their immediate environment, without relying exclusively on Vision. </p>\n<p>Additionally, a spatial audio file is played from the pointer\u2019s position on the environment mesh. Like an Audible Pedestrian Crossing, this sound allows the CleARsight wearer to hear, in real space, their distance from the obstacle.\nOperating concurrently, this synchronized combination of haptics, spatial audio and High-Visibility Holographic outlines serve to supplement the CleARsight wearer\u2019s reliance on Visual Navigation. </p>\n<p>In the home, and other familiar locations, CleARsight allows the recording of contextual \u2018Placed Audio Memos.\u2019 Spatially affixed to their recording location, CleARsight wearers, or their caregivers can drop a message of their choosing, which will automatically playback when approached. \nToday, CleARsight introduces a novel use of Spatial Computing technology, to amplify the wearer\u2019s senses. Tomorrow, improvements to this technology can be built upon with other digital integrations like Object Recognition, Voice Recognition, and IoT Controls to bolster a robust Sightless User Interface. </p>\n<h2>What's Next For the Project</h2>\n<p>We'd like to continue to extend the feature set of this application and further bolster its usability with additional user testing and integrations to further improve its offering to low vision individuals.</p>\n<p>Some examples are:\n<em>Dynamic Object Recognition</em></p>\n<ul>\n<li>Spatial Mapping data persistently analyzed, matching and expanding 3D Object Database for on-demand contextual information and passive Machine Learning Training.</li>\n</ul>\n<p><em>Voice Recognition</em></p>\n<ul>\n<li>Custom voice-triggered commands, Action events (confirm, cancel, etc.), Speech-To-Text parsing and Personal Assistant integration. </li>\n</ul>\n<p><em>IoT, Home &amp; Ecosystem Integration</em></p>\n<ul>\n<li>Open-Source API &amp; SDK for developers to implement in products and services. </li>\n</ul>\n<p><em>Geospatial Positional Synchronization</em></p>\n<ul>\n<li>Landmarks, known paths, obstacles and other context-sensitive annotations. </li>\n</ul>\n<p><em>High-Speed &amp; Hazard Warnings</em> </p>\n<ul>\n<li>Detect high-speed movement alarm for vehicles, cliffed overhangs and environmental obstructions. </li>\n</ul>\n<p>Slide Deck: <a href=\"https://www.slideshare.net/keithbradley1/magic-leap-accessibility-app-for-low-vision\" rel=\"nofollow\">link</a></p>\n</div>",
    "content_md": "\n## Inspiration\n\n\nAccording to the National Center for Health Statistics, 26 Million Americans Adults experience significant vision loss, creating challenges with Depth Perception, Low-Light scenarios and proprioception. CleARsight for Magic Leap is a Spatial Computing Accessibility application, to improve the daily lives of individuals with Low Vision. \n\n\n## What it does\n\n\nUsing Magic Leap\u2019s World Mapping, Haptic Feedback, Spatial Audio, and Holographic Visual Overlay, CleARsight illuminates your environment, outlining object edges with High Contrast colours, and highlighting horizontal planes with a vivid pattern. \n\n\nPulling the trigger of the 6DoF Controller, activates the environmental awareness system \u2018virtual cane.\u2019 Measuring the distance between the Controller, and the spatial mesh generated by the magic leap\u2019s world reconstruction system, Haptic feedback increases in intensity as obstacles get closer. Like the use of echo-location in nature, this allows the CleARsight wearer to gain a spatial understanding of their immediate environment, without relying exclusively on Vision. \n\n\nAdditionally, a spatial audio file is played from the pointer\u2019s position on the environment mesh. Like an Audible Pedestrian Crossing, this sound allows the CleARsight wearer to hear, in real space, their distance from the obstacle.\nOperating concurrently, this synchronized combination of haptics, spatial audio and High-Visibility Holographic outlines serve to supplement the CleARsight wearer\u2019s reliance on Visual Navigation. \n\n\nIn the home, and other familiar locations, CleARsight allows the recording of contextual \u2018Placed Audio Memos.\u2019 Spatially affixed to their recording location, CleARsight wearers, or their caregivers can drop a message of their choosing, which will automatically playback when approached. \nToday, CleARsight introduces a novel use of Spatial Computing technology, to amplify the wearer\u2019s senses. Tomorrow, improvements to this technology can be built upon with other digital integrations like Object Recognition, Voice Recognition, and IoT Controls to bolster a robust Sightless User Interface. \n\n\n## What's Next For the Project\n\n\nWe'd like to continue to extend the feature set of this application and further bolster its usability with additional user testing and integrations to further improve its offering to low vision individuals.\n\n\nSome examples are:\n*Dynamic Object Recognition*\n\n\n* Spatial Mapping data persistently analyzed, matching and expanding 3D Object Database for on-demand contextual information and passive Machine Learning Training.\n\n\n*Voice Recognition*\n\n\n* Custom voice-triggered commands, Action events (confirm, cancel, etc.), Speech-To-Text parsing and Personal Assistant integration.\n\n\n*IoT, Home & Ecosystem Integration*\n\n\n* Open-Source API & SDK for developers to implement in products and services.\n\n\n*Geospatial Positional Synchronization*\n\n\n* Landmarks, known paths, obstacles and other context-sensitive annotations.\n\n\n*High-Speed & Hazard Warnings* \n\n\n* Detect high-speed movement alarm for vehicles, cliffed overhangs and environmental obstructions.\n\n\nSlide Deck: [link](https://www.slideshare.net/keithbradley1/magic-leap-accessibility-app-for-low-vision)\n\n\n"
}